{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module3_Demo2_Analysing_Sentiment_With_OHE.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maria-gpe-a/implement-nlp-word-embedding/blob/main/module3/Module3_Demo2_Analysing_Sentiment_With_OHE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysing Sentiment"
      ],
      "metadata": {
        "id": "QlJeKdJfTPMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first import everything and load the dataset"
      ],
      "metadata": {
        "id": "epE01e6NbbMg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri00gAaqSzrq",
        "outputId": "976dd1e7-deb7-4250-f9f3-1ad3e2606a74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from textblob import TextBlob, Word\n",
        "import nltk\n",
        "import torch\n",
        "from torch import nn\n",
        "import seaborn as sns\n",
        "nltk.download('punkt')\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set(rc={'figure.figsize':(20,20)})\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile get_data.sh\n",
        "#if [ ! -f yelp.csv ]; then\n",
        "#  wget https://raw.githubusercontent.com/axel-sirota/implement-nlp-word-embedding/main/module3/data/yelp.csv\n",
        "#fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHuUsDMlTXhM",
        "outputId": "611fd60c-0bf7-43b1-fb65-9d04a2c0baef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting get_data.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!bash get_data.sh\n"
      ],
      "metadata": {
        "id": "Uq4-oO3KTnbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './yelp.csv'\n",
        "yelp = pd.read_csv(path)\n",
        "# Create a new DataFrame that only contains the 5-star and 1-star reviews.\n",
        "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]\n",
        "\n",
        "# Define X and y.\n",
        "X = yelp_best_worst.text\n",
        "y = yelp_best_worst.stars.map({1:0, 5:1})\n"
      ],
      "metadata": {
        "id": "i32aK_G6TZl9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Doing the train_test split and defining model"
      ],
      "metadata": {
        "id": "quWimVZjbemw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
        "print(X_train)"
      ],
      "metadata": {
        "id": "gPK5YmDMTbby",
        "outputId": "52335e49-13a3-4402-eb2f-e43ce2c223ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5307    If I could give it more than 5, I would.  Swee...\n",
            "5985    We had a fantastic experience here! We went on...\n",
            "6918    4 stars for the place itself and it's food/cof...\n",
            "4315    I'm a huge fan of Padre's! What food I've trie...\n",
            "3356    I love this place. I just tried the other Ethi...\n",
            "                              ...                        \n",
            "2737    Let me tell you about my first crush in Phoeni...\n",
            "3142    My dear love and I went to the museum on a rom...\n",
            "2065    You like hotdogs?  Motor (thats me) says get i...\n",
            "8596    Nice facilities, nice AC, but two FATAL flaws:...\n",
            "7787    The single best ribs I've ever had at any rest...\n",
            "Name: text, Length: 3268, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vect = CountVectorizer()\n",
        "X_train_dtm = vect.fit_transform(X_train)\n",
        "X_test_dtm = vect.transform(X_test)"
      ],
      "metadata": {
        "id": "v0LSrnpiUs8p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_dtm.shape)\n",
        "print(X_test_dtm.shape)"
      ],
      "metadata": {
        "id": "UU63y6O2xQ1I",
        "outputId": "60af5713-e243-469a-b8aa-f6baf3596468",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3268, 17181)\n",
            "(818, 17181)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_dtm[1,:].toarray())\n"
      ],
      "metadata": {
        "id": "NGrnjv6xxiap",
        "outputId": "3d0be0cc-082c-4cae-c941-b164a732cb32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.Tensor(X_train_dtm.toarray()).to(device)\n",
        "X_test_tensor = torch.Tensor(X_test_dtm.toarray()).to(device)\n",
        "y_train = torch.Tensor(y_train.values).type(torch.LongTensor).to(device)\n",
        "y_test = torch.Tensor(y_test.values).type(torch.LongTensor).to(device)"
      ],
      "metadata": {
        "id": "SwdtffgTVRM0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "  nn.Linear(X_train_tensor.shape[1], 2),\n",
        "  nn.LogSoftmax(dim = 1)\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "Ip1U599PVXrg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(X):\n",
        "  return model(X).to(device)\n",
        "\n",
        "def loss(y_pred, y):\n",
        "  return nn.functional.nll_loss(y_pred, y)\n",
        "\n",
        "def metric(y_pred, y):  # -> accuracy\n",
        "  return (1 / len(y)) * ((y_pred.argmax(dim = 1) == y).sum())\n"
      ],
      "metadata": {
        "id": "RB_PGA_7WTC5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's verify the metric makes sense"
      ],
      "metadata": {
        "id": "KMQJasS-YOpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model(X_train_tensor).to(device)\n",
        "y_train_pred.argmax(dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbKjRHJyWbTU",
        "outputId": "b6664490-4a22-422f-dc9c-c0d0fa2a137e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(y_train_pred.argmax(dim = 1) == y_train).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qnE5Aj0WfoX",
        "outputId": "5d4eb554-7526-4ddd-8f62-7987d23069a6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1164, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric(y_train_pred, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMIbTz7mWm-v",
        "outputId": "a9ba669e-85ac-49f4-ef11-56bea7c76c59"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3562, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del y_train_pred"
      ],
      "metadata": {
        "id": "JD4jGHO3YelM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The training routine"
      ],
      "metadata": {
        "id": "ROXVUovhYRWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters())"
      ],
      "metadata": {
        "id": "U80Pu2e8X3Il"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n",
        "print(model.parameters())"
      ],
      "metadata": {
        "id": "yWrBlvV4nUxn",
        "outputId": "b0b9bebc-ea72-459b-ad76-e1b3aaaa5287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=17181, out_features=2, bias=True)\n",
            "  (1): LogSoftmax(dim=1)\n",
            ")\n",
            "<generator object Module.parameters at 0x7a738272b5a0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "for i in range(epochs):\n",
        "  y_pred = forward(X_train_tensor)\n",
        "  xe = loss(y_pred, y_train)\n",
        "  #print(xe)\n",
        "  #print(xe.backward)\n",
        "  accuracy = metric(y_pred, y_train)\n",
        "  xe.backward()\n",
        "  if i % 100 == 0:\n",
        "   print(\"Loss: \", xe, \" Accuracy \", accuracy.data.item())\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kchBdsMYT94",
        "outputId": "91d16614-473d-437b-d460-b55b6fa49695"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  1.0\n",
            "Loss:  tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  1.0\n",
            "Loss:  tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  1.0\n",
            "Loss:  tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  1.0\n",
            "Loss:  tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  1.0\n",
            "Loss:  tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  1.0\n",
            "Loss:  tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  1.0\n",
            "Loss:  tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  1.0\n",
            "Loss:  tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  1.0\n",
            "Loss:  tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)  Accuracy  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = forward(X_test_tensor)\n",
        "print(f'Model accuracy is {metric(y_test_pred, y_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlU4QbIPYrPc",
        "outputId": "c7f111fd-7b9f-4661-ee90-4df062be4a52"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy is 0.9009780287742615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some manual validation"
      ],
      "metadata": {
        "id": "tNqRJ0wCbXMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review = np.array([\"This place was fantastic\"])\n",
        "vectorized_review = torch.Tensor(vect.transform(review).toarray()).to(device)"
      ],
      "metadata": {
        "id": "EgO7d2LdbYhD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = forward(vectorized_review)\n",
        "prediction.argmax(dim = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icVOjVFybsU-",
        "outputId": "3359597e-2d6a-477d-ab4e-9cc67f91eebd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, the model predicted correctly that the review was positive!"
      ],
      "metadata": {
        "id": "VBSc6m2LcPfk"
      }
    }
  ]
}